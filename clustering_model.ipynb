{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2997827",
   "metadata": {},
   "source": [
    "# Clustering on DeepFold Embeddings\n",
    "Haerang Lee\n",
    "\n",
    "I'm going to take Skyler's DeepFold embeddings. Those files are in `embeddings/DeepFold` in the GCS bucket.\n",
    "\n",
    "Then let me run some clustering models on top of it.\n",
    "\n",
    "**Silly question**: If I want to put this notebook under a directory, how do I access `utils` in the parent directory? Right now I just put my notebook in the home dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31305d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import argparse\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils import gcs_utils as gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e064b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the keys from gcs\n",
    "allkeys = gcs.list_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41f78067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/annotations/blast_annotations.csv',\n",
       " 'UP000005640_9606_HUMAN.tar',\n",
       " 'UP000005640_9606_HUMAN/cif/AF-A0A024R1R8-F1-model_v1.cif.gz',\n",
       " 'UP000005640_9606_HUMAN/cif/AF-A0A024RBG1-F1-model_v1.cif.gz',\n",
       " 'UP000005640_9606_HUMAN/cif/AF-A0A024RCN7-F1-model_v1.cif.gz',\n",
       " 'UP000005640_9606_HUMAN/cif/AF-A0A075B6H5-F1-model_v1.cif.gz',\n",
       " 'UP000005640_9606_HUMAN/cif/AF-A0A075B6H7-F1-model_v1.cif.gz',\n",
       " 'UP000005640_9606_HUMAN/cif/AF-A0A075B6H8-F1-model_v1.cif.gz',\n",
       " 'UP000005640_9606_HUMAN/cif/AF-A0A075B6H9-F1-model_v1.cif.gz',\n",
       " 'UP000005640_9606_HUMAN/cif/AF-A0A075B6I0-F1-model_v1.cif.gz']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's in here?\n",
    "allkeys[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48398bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46812"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many files are there?\n",
    "len(allkeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68dda701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings/\n",
      "embeddings/DeepFold/\n",
      "embeddings/DeepFold/embeddings_0.csv\n",
      "embeddings/DeepFold/embeddings_1.csv\n",
      "embeddings/DeepFold/embeddings_10.csv\n",
      "embeddings/DeepFold/embeddings_11.csv\n",
      "embeddings/DeepFold/embeddings_12.csv\n",
      "embeddings/DeepFold/embeddings_13.csv\n",
      "embeddings/DeepFold/embeddings_14.csv\n",
      "embeddings/DeepFold/embeddings_15.csv\n",
      "embeddings/DeepFold/embeddings_16.csv\n",
      "embeddings/DeepFold/embeddings_17.csv\n",
      "embeddings/DeepFold/embeddings_18.csv\n",
      "embeddings/DeepFold/embeddings_19.csv\n",
      "embeddings/DeepFold/embeddings_2.csv\n",
      "embeddings/DeepFold/embeddings_20.csv\n",
      "embeddings/DeepFold/embeddings_21.csv\n",
      "embeddings/DeepFold/embeddings_22.csv\n",
      "embeddings/DeepFold/embeddings_23.csv\n",
      "embeddings/DeepFold/embeddings_3.csv\n",
      "embeddings/DeepFold/embeddings_4.csv\n",
      "embeddings/DeepFold/embeddings_5.csv\n",
      "embeddings/DeepFold/embeddings_6.csv\n",
      "embeddings/DeepFold/embeddings_7.csv\n",
      "embeddings/DeepFold/embeddings_8.csv\n",
      "embeddings/DeepFold/embeddings_9.csv\n"
     ]
    }
   ],
   "source": [
    "# I just want the DeepFold embedding files\n",
    "for k in allkeys:\n",
    "    if \"embed\" in k:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c7ecc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'embeddings/DeepFold'\n",
    "keys = gcs.list_file_paths(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc7dc1b",
   "metadata": {},
   "source": [
    "There are 24 files in the embeddings folder, each containing 1,000 proteins (except the last one). Here are the file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63614748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://capstone-fall21-protein/embeddings/DeepFold/',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_0.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_1.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_10.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_11.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_12.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_13.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_14.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_15.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_16.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_17.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_18.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_19.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_2.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_20.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_21.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_22.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_23.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_3.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_4.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_5.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_6.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_7.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_8.csv',\n",
       " 'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_9.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e7be9e",
   "metadata": {},
   "source": [
    "One of those embeddings files contains 1,000 proteins.\n",
    "The first three elements appear to be empty data, or just `'', '0', '1\\n0'`. The remaining 2,000 are pairs of protein name and relevant embedding (2\\*1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "923ea197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://capstone-fall21-protein/embeddings/DeepFold/embeddings_0.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1259d68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'embeddings/DeepFold/embeddings_7.csv'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = gcs.uri_to_bucket_and_key(keys[22])[1]\n",
    "key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37027a12",
   "metadata": {},
   "source": [
    "## Download and Parse DeepFold Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "febd6411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let me download one and play with it.\n",
    "df_emb = gcs.download_text(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d085e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode it then split it into a list.\n",
    "df_emb_decode = df_emb.decode('utf-8').split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b95e8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2003"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2003 items, where the first few are not just metadata or empty strings\n",
    "len(df_emb_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c2a7e980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '0', '1\\n0', 'AF-P52758-F1-model_v1']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Item index 3 is where the real data starts. That's the protein name.\n",
    "df_emb_decode[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5269054a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"[0.02314364 0.         0.         0.         0.         0.\\n 0.21306136 0.         0.         0.         0.         0.\\n 0.00894155 0.14864615 0.         0.16724743 0.         0.\\n 0.         0.         0.14527881 0.         0.05551712 0.01512884\\n 0.         0.         0.         0.03125526 0.         0.\\n 0.08913685 0.         0.         0.         0.         0.\\n 0.13471818 0.         0.         0.         0.         0.11604603\\n 0.         0.         0.0529888  0.00097862 0.         0.\\n 0.         0.         0.00811869 0.         0.         0.02698607\\n 0.         0.         0.         0.         0.07556766 0.\\n 0.18254162 0.00297375 0.         0.         0.         0.\\n 0.         0.         0.02795849 0.         0.         0.06582197\\n 0.         0.         0.04518154 0.         0.         0.\\n 0.         0.         0.07439934 0.         0.1683139  0.\\n 0.         0.         0.01760291 0.         0.07878704 0.01621049\\n 0.         0.12183473 0.         0.02944913 0.         0.\\n 0.14381258 0.02073403 0.07590045 0.         0.         0.\\n 0.         0.01363126 0.07208093 0.         0.         0.\\n 0.         0.12615182 0.         0.         0.         0.14108258\\n 0.         0.         0.         0.         0.04168807 0.\\n 0.         0.06576484 0.         0.         0.         0.\\n 0.         0.00971658 0.05059295 0.06317799 0.         0.\\n 0.03253891 0.         0.         0.         0.         0.\\n 0.00962644 0.         0.         0.         0.         0.\\n 0.00792778 0.03608674 0.03793285 0.12598439 0.         0.10180479\\n 0.         0.1096139  0.03835648 0.         0.0555568  0.\\n 0.         0.0545046  0.         0.         0.         0.\\n 0.         0.         0.02885103 0.         0.00431074 0.\\n 0.05139066 0.         0.30635807 0.         0.00679156 0.\\n 0.09452131 0.         0.         0.         0.13394403 0.09762918\\n 0.         0.02310242 0.         0.         0.06708985 0.\\n 0.         0.06497151 0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.02407264 0.         0.         0.\\n 0.         0.         0.05431239 0.         0.         0.05462025\\n 0.10273146 0.08540751 0.         0.00790119 0.         0.\\n 0.169093   0.         0.         0.         0.04370213 0.\\n 0.         0.12707384 0.         0.         0.         0.01961581\\n 0.         0.         0.         0.02918626 0.         0.\\n 0.         0.0036897  0.01159351 0.         0.06846355 0.\\n 0.         0.         0.         0.02200389 0.         0.02000592\\n 0.         0.         0.0318802  0.09190645 0.         0.\\n 0.         0.0169356  0.19742802 0.02531848 0.08357864 0.00223953\\n 0.         0.         0.04056058 0.05070694 0.         0.\\n 0.25617096 0.         0.         0.         0.         0.\\n 0.         0.05889191 0.         0.         0.         0.03604541\\n 0.         0.         0.         0.1064846  0.08369392 0.14878869\\n 0.         0.00135816 0.10710653 0.         0.         0.\\n 0.         0.11444912 0.         0.         0.         0.02669412\\n 0.         0.01393781 0.         0.07296172 0.         0.\\n 0.         0.         0.         0.         0.         0.04067323\\n 0.         0.         0.         0.         0.0231672  0.\\n 0.         0.         0.04752928 0.03145236 0.00324641 0.\\n 0.         0.02926644 0.00244213 0.         0.09553625 0.\\n 0.01650584 0.07412088 0.11087363 0.         0.         0.\\n 0.         0.01643748 0.         0.         0.01589641 0.\\n 0.05473797 0.         0.02218097 0.0710637  0.0212361  0.25800192\\n 0.         0.         0.         0.         0.         0.\\n 0.13236551 0.         0.         0.         0.         0.\\n 0.00063163 0.         0.         0.         0.         0.08648559\\n 0.04083654 0.01081329 0.09609775 0.         0.11838535 0.07038995\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.08174036 0.         0.         0.02403302 0.         0.06239022\\n 0.04072979 0.         0.         0.01147999 0.         0.00352042\\n 0.01732604 0.         0.02485226 0.         0.02280044 0.\\n 0.         0.        ]\"\\n1'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... Followed by the 398-length vector that represents a DeepFold embedding\n",
    "df_emb_decode[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aad8e474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's figure out how to parse the DeepFold embedding. \n",
    "# There's a lot of funny stuff in here.\n",
    "# First, get rid of the file number at the end and just keep the vector\n",
    "\n",
    "sample_emb = df_emb_decode[6].rsplit('\\n', 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cf96008b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.', '0.', '0.', '0.', '0.05980834', '0.', '0.11338624',\n",
       "       '0.03886417', '0.02524441', '0.', '0.', '0.', '0.', '0.05950396',\n",
       "       '0.01365902', '0.12355073', '0.00876983', '0.01822875',\n",
       "       '0.09609001', '0.04257268', '0.04186481', '0.02684545',\n",
       "       '0.03763113', '0.', '0.03659998', '0.', '0.', '0.', '0.059562',\n",
       "       '0.', '0.06115272', '0.1620137', '0.03983198', '0.01684552',\n",
       "       '0.02932842', '0.00660839', '0.00770707', '0.04277336',\n",
       "       '0.01949005', '0.', '0.', '0.', '0.', '0.04254051', '0.07754262',\n",
       "       '0.02618456', '0.', '0.', '0.', '0.', '0.', '0.', '0.01862345',\n",
       "       '0.', '0.04642207', '0.', '0.', '0.07284059', '0.06610846',\n",
       "       '0.12522222', '0.', '0.', '0.', '0.03716445', '0.', '0.',\n",
       "       '0.04749022', '0.', '0.03763493', '0.0703754', '0.', '0.',\n",
       "       '0.02273948', '0.', '0.00482177', '0.03592151', '0.', '0.', '0.',\n",
       "       '0.', '0.00829109', '0.02022448', '0.12619579', '0.', '0.', '0.',\n",
       "       '0.06418524', '0.', '0.', '0.09890323', '0.', '0.', '0.00144561',\n",
       "       '0.', '0.09147837', '0.06295256', '0.00653698', '0.', '0.12657993',\n",
       "       '0.', '0.', '0.04163909', '0.', '0.', '0.', '0.02829257',\n",
       "       '0.04039153', '0.06628565', '0.', '0.0087872', '0.0084249',\n",
       "       '0.03270797', '0.14450833', '0.', '0.00741809', '0.', '0.04919405',\n",
       "       '0.', '0.', '0.13808498', '0.09374839', '0.', '0.12582865',\n",
       "       '0.01426593', '0.', '0.15031183', '0.02470017', '0.', '0.03085166',\n",
       "       '0.04417508', '0.0006746', '0.03350945', '0.01194865',\n",
       "       '0.05489074', '0.', '0.07116625', '0.', '0.', '0.', '0.', '0.',\n",
       "       '0.', '0.', '0.01899349', '0.', '0.07686512', '0.', '0.06435193',\n",
       "       '0.', '0.', '0.', '0.15322883', '0.', '0.09604248', '0.02390816',\n",
       "       '0.08016782', '0.', '0.04388826', '0.13394573', '0.', '0.06688856',\n",
       "       '0.', '0.02585234', '0.1017904', '0.0282887', '0.', '0.', '0.',\n",
       "       '0.', '0.01998496', '0.05055141', '0.09936758', '0.', '0.',\n",
       "       '0.17462678', '0.05487485', '0.', '0.', '0.08260254', '0.04759179',\n",
       "       '0.', '0.', '0.', '0.00697605', '0.03123792', '0.', '0.04067155',\n",
       "       '0.08182963', '0.', '0.', '0.', '0.', '0.02955717', '0.',\n",
       "       '0.00343344', '0.03440702', '0.', '0.', '0.06064336', '0.',\n",
       "       '0.04429209', '0.11123917', '0.', '0.', '0.08772237', '0.08640277',\n",
       "       '0.', '0.02345176', '0.15484817', '0.', '0.05288275', '0.', '0.',\n",
       "       '0.', '0.', '0.', '0.11364133', '0.', '0.01076936', '0.03315537',\n",
       "       '0.12002372', '0.03057418', '0.03092458', '0.', '0.00837152',\n",
       "       '0.00635424', '0.', '0.', '0.', '0.', '0.', '0.07709942',\n",
       "       '0.03182171', '0.', '0.01376555', '0.01781355', '0.03038462', '0.',\n",
       "       '0.', '0.', '0.00578539', '0.', '0.09882674', '0.01823773', '0.',\n",
       "       '0.03258087', '0.', '0.02911014', '0.03968379', '0.', '0.03894253',\n",
       "       '0.00932875', '0.08347307', '0.03994662', '0.17834936',\n",
       "       '0.09543647', '0.', '0.', '0.', '0.', '0.05920684', '0.07714174',\n",
       "       '0.04363203', '0.03916556', '0.02598635', '0.', '0.06922439', '0.',\n",
       "       '0.', '0.', '0.', '0.18209377', '0.02272743', '0.05665448', '0.',\n",
       "       '0.04883811', '0.', '0.07745793', '0.', '0.0973512', '0.',\n",
       "       '0.02732183', '0.03171235', '0.11221045', '0.', '0.0436484', '0.',\n",
       "       '0.', '0.', '0.', '0.01079782', '0.', '0.04995101', '0.08127663',\n",
       "       '0.', '0.01610788', '0.', '0.00311978', '0.', '0.', '0.08783942',\n",
       "       '0.0316363', '0.', '0.', '0.10540186', '0.08023261', '0.01441455',\n",
       "       '0.02311896', '0.', '0.', '0.', '0.06996151', '0.15908292',\n",
       "       '0.01964344', '0.', '0.04563855', '0.', '0.02551155', '0.', '0.',\n",
       "       '0.02156669', '0.07118768', '0.', '0.', '0.', '0.', '0.06478353',\n",
       "       '0.', '0.', '0.', '0.04115181', '0.', '0.08003301', '0.', '0.',\n",
       "       '0.', '0.', '0.08841439', '0.04027123', '0.', '0.02714846',\n",
       "       '0.09262609', '0.', '0.05707483', '0.00997529', '0.17844826', '0.',\n",
       "       '0.', '0.03517175', '0.1809456', '0.02974886', '0.', '0.',\n",
       "       '0.0219439', '0.01037093', '0.04509848', '0.', '0.04460922',\n",
       "       '0.02651942', '0.', '0.', '0.', '0.', '0.08297099', '0.1446617',\n",
       "       '0.', '0.', '0.', '0.0002086', '0.02008559', '0.06630368',\n",
       "       '0.18600738', '0.03415132', '0.02067097', '0.01145675', '0.', '0.',\n",
       "       '0.03768767', '0.01105373', '0.', '0.', '0.', '0.', '0.06230666',\n",
       "       '0.04061314', '0.', '0.', '0.', '0.04654699', '0.03952103', '0.',\n",
       "       '0.10568485', '0.', '0.', '0.08500329', '0.03520707', '0.', '0.'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now get rid of the double quotes and brackets to just get the values of the array\n",
    "\n",
    "sample_emb_np = np.array(sample_emb[2:-2].split())\n",
    "sample_emb_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6d335c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398,)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size is as expected \n",
    "\n",
    "sample_emb_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "429af87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AF-P52758-F1-model_v1'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# items 0-2 in the embedding file are not relevant. \n",
    "# Take the rest and convert into a numpy array \n",
    "    # First column is the protein names\n",
    "    # Second  column is the DeepFold. vector (size 398)\n",
    "\n",
    "np_emb = np.array(df_emb_decode[3:]).reshape(1000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c3b7fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take those columns separately to clean it up\n",
    "\n",
    "X=np_emb[:,1].reshape(1000,1)\n",
    "protein=np_emb[:,0].reshape(1000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "506e373c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c48d9",
   "metadata": {},
   "source": [
    "## Parsing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "355d0cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_deepfold_embedding(unparsed):\n",
    "    \"\"\"Given a single DeepFold vector in a text format, \n",
    "    drop the metadata and convert the into a numpy array.\"\"\"\n",
    "    \n",
    "    return np.array([float(n) for n in unparsed[0].rsplit('\\n', 1)[0][2:-2].split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d1a17bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the custom parse function. \n",
    "# The result is in a list.\n",
    "\n",
    "parsed_list = list(map(parse_deepfold_embedding, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66df301f",
   "metadata": {},
   "source": [
    "# Proteins that are missing DeepFold emeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c0263095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately, not every protein has a 398-D embedding.\n",
    "# Let's find those out. \n",
    "\n",
    "missing=[]\n",
    "for i in range(len(parsed_list)):\n",
    "    if len(parsed_list[i])!= 398:\n",
    "        missing.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "59368976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AF-P53803-F1-model_v1', 'AF-P56378-F1-model_v1',\n",
       "       'AF-P56381-F1-model_v1', 'AF-P58511-F1-model_v1',\n",
       "       'AF-P62273-F1-model_v1', 'AF-P62328-F1-model_v1',\n",
       "       'AF-P62891-F1-model_v1', 'AF-P62945-F1-model_v1',\n",
       "       'AF-P63313-F1-model_v1', 'AF-P80294-F1-model_v1',\n",
       "       'AF-P80297-F1-model_v1', 'AF-P84101-F1-model_v1',\n",
       "       'AF-Q00LT1-F1-model_v1'], dtype='<U6076')"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These proteisns are missing DeepFold embeddings\n",
    "\n",
    "np_emb[missing, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "12e9a4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(embedding) for embedding in np_emb[missing, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "3e9ef307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n60', '\\n220', '\\n221', '\\n340', '\\n551', '\\n563', '\\n600',\n",
       "       '\\n608', '\\n648', '\\n781', '\\n782', '\\n834', '\\n987'],\n",
       "      dtype='<U6076')"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_emb[missing, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "351c69c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "a4aa82f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(987, 398)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's generate a clean dataset by eliminating the proteins with missing embeddings \n",
    "# We end up with 987 out of 1,000 proteins. \n",
    "\n",
    "X_clean = np.stack([x for i,x in enumerate(parsed_list) if i not in missing])\n",
    "X_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "4d9e992f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(987, 1)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_clean =  np.stack([x for i,x in enumerate(protein) if i not in missing])\n",
    "protein_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a252a808",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "3b1ad106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "clustering = DBSCAN(eps=0.5, min_samples=5).fit(X_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "3341ac6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1 552]\n",
      " [  0   5]\n",
      " [  1 257]\n",
      " [  2  21]\n",
      " [  3  33]\n",
      " [  4   5]\n",
      " [  5  40]\n",
      " [  6  26]\n",
      " [  7  20]\n",
      " [  8   8]\n",
      " [  9   8]\n",
      " [ 10  12]]\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(np.unique(clustering.labels_, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538d9f1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Hyperparam tuning\n",
    "\n",
    "Next steps for me:\n",
    "1. I’m going to add in some form of evaluation metrics. Exploring using BLAST or other more traditional cluster evaluation techniques like the Elbow method. Then I’ll try to figure out what a reasonable outcome means and how to optimize for it.\n",
    "1. I’ll write the code to tune the hyperparams.\n",
    "1. Finally, I am going to write a .py file to download all the proteins and run a DB scan on all the proteins, then tune the hyperparams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd18299",
   "metadata": {},
   "source": [
    "## Ideal number of clusters for the data\n",
    "\n",
    "\n",
    "DBSCAN takes two inputs: `eps` and `min_samples`. Since this is an unsupervised model, here are some validity functions I can use to determine the right hyperparam values. \n",
    "\n",
    "First, let me try the Silhouette coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "57fbcd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "77d57c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples = 5: 0.0878836258259686\n",
      "min_samples = 10: 0.09233013108149128\n",
      "min_samples = 15: 0.0931771750487543\n",
      "min_samples = 20: 0.09302338428730225\n",
      "min_samples = 25: 0.09592920073634915\n",
      "min_samples = 30: 0.09522166192796085\n",
      "min_samples = 35: 0.09503834723374222\n",
      "min_samples = 40: 0.09623713712167237\n",
      "min_samples = 45: 0.09623713712167237\n",
      "min_samples = 50: 0.0965156529388127\n",
      "min_samples = 55: 0.09798522659017606\n",
      "min_samples = 60: 0.09615374573902442\n",
      "min_samples = 65: 0.09707610885170077\n",
      "min_samples = 70: 0.09736258993747669\n",
      "min_samples = 75: 0.09768536284564597\n",
      "min_samples = 80: 0.09777008789765693\n",
      "min_samples = 85: 0.09847861209642206\n",
      "min_samples = 90: 0.10008703778391964\n",
      "min_samples = 95: 0.10021354866502505\n",
      "min_samples = 100: 0.09867890593139018\n",
      "min_samples = 105: 0.09945751277936156\n",
      "min_samples = 110: 0.09945751277936156\n",
      "min_samples = 115: 0.09945751277936156\n",
      "min_samples = 120: 0.09975458237952906\n",
      "min_samples = 125: 0.09957527231470707\n",
      "min_samples = 130: 0.09957527231470707\n",
      "min_samples = 135: 0.09957527231470707\n",
      "min_samples = 140: 0.09940835589336891\n",
      "min_samples = 145: 0.09946289892647467\n",
      "min_samples = 150: 0.09968969400558335\n",
      "min_samples = 155: 0.09994635643362708\n",
      "min_samples = 160: 0.09994635643362708\n",
      "min_samples = 165: 0.09996879475275447\n",
      "min_samples = 170: 0.09996879475275447\n",
      "min_samples = 175: 0.10019600298927343\n",
      "min_samples = 180: 0.10019600298927343\n",
      "min_samples = 185: 0.10019600298927343\n",
      "min_samples = 190: 0.099843383104516\n",
      "min_samples = 195: 0.10160599481999856\n"
     ]
    }
   ],
   "source": [
    "# Let's just use my data from above, where the size is 987.\n",
    "range_min_samples = range(5, 200, 5)\n",
    "\n",
    "for n in range_min_samples:\n",
    "    clustering = DBSCAN(eps=1, min_samples=n).fit(X_clean)\n",
    "    cluster_labels = clustering.labels_\n",
    "    \n",
    "    silhouette_avg = silhouette_score(X_clean, cluster_labels)\n",
    "    print(\"min_samples = \" + str(n) + \":\", str(silhouette_avg))\n",
    "    \n",
    "    sample_silhouette_values = silhouette_samples(X_clean, cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "1643d9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(987,)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_silhouette_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86f460",
   "metadata": {},
   "source": [
    "## Euclidean distances between points\n",
    "\n",
    "The parameter `eps` in DBSCAN represents the distance threshold below which the two points are considered neighbors to each other. I have no idea what the range of distances look like, so let me find out. \n",
    "\n",
    "A thorough way to do this is to find out the distance between every point and every other point. Given I have 1,000 points, I'll get 1,000^2 distances. It's OK to do with 1,000 points but may cause an issue with 23,000. We'll see.\n",
    "\n",
    "Let me do the proper way first. Then, if I need to optimize it later, I'll sample and find the epsilons from the 23,000 full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "acba05ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(987, 398)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4416a81e",
   "metadata": {},
   "source": [
    "`sklearn.metrics.pairwise.euclidean_distances` calculates the euclidean distance between a pair of row vector x and y is computed as:\n",
    "```dist(x, y) = sqrt(dot(x, x) - 2 * dot(x, y) + dot(y, y))```\n",
    "\n",
    "> However, this is not the most precise way of doing this computation, because this equation potentially suffers from “catastrophic cancellation”. Also, the distance matrix returned by this function may not be exactly symmetric as required by, e.g., scipy.spatial.distance functions.\n",
    "\n",
    "Not sure what that means, but I'll figure it out.\n",
    "\n",
    "[source](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.euclidean_distances.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "fedd9c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(987, 987)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "ed = euclidean_distances(X_clean, X_clean)\n",
    "ed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b4b63b",
   "metadata": {},
   "source": [
    "So now I have a 987 by 987 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "d15526af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_ed = np.min(ed)\n",
    "min_ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "f34772b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4114782477784376"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ed = np.max(ed)\n",
    "max_ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "297665db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.203486147373727"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "0f96bbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(range(0,987**2), np.sort(ed.flatten()))\n",
    "plt.axvline(987**2/2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc63e146",
   "metadata": {},
   "source": [
    "The euclidean distance among my 987 proteins range from 0 to 1.41, median is about 1.2. If I expect there to be 10-50 clusters within a dataset of 1,000 proteins, then I think my epsilon has got to be much smaller than this median. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155bc714",
   "metadata": {},
   "source": [
    "Try different epsilons now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "461dbdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 0.1: Everything is a noise!\n",
      "eps = 0.2: -0.0065\n",
      "eps = 0.3: -0.1116\n",
      "eps = 0.4: 0.0274\n",
      "eps = 0.5: 0.0745\n",
      "eps = 0.6: 0.1006\n",
      "eps = 0.7: 0.0621\n",
      "eps = 0.8: 0.0858\n",
      "eps = 0.9: 0.0836\n",
      "eps = 1.0: 0.0923\n"
     ]
    }
   ],
   "source": [
    "range_eps = np.linspace(start=0.1, stop=1.0, num=10)\n",
    "\n",
    "for n in range_eps:\n",
    "    clustering = DBSCAN(eps=n, min_samples=10).fit(X_clean)\n",
    "    cluster_labels = clustering.labels_\n",
    "    \n",
    "    if len(np.unique(cluster_labels))==1:\n",
    "        print(\"eps = \" + str(round(n, 2)) + \": Everything is a noise!\")\n",
    "    else:\n",
    "        silhouette_avg = silhouette_score(X_clean, cluster_labels)\n",
    "        print(\"eps = \" + str(round(n, 2)) + \":\", \n",
    "              str(round(silhouette_avg, 4)))\n",
    "\n",
    "        sample_silhouette_values = silhouette_samples(X_clean, cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd499a61",
   "metadata": {},
   "source": [
    "Now let's try doing a manual grid search. We want to maximize the silouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "e75acb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps=0.1, min_samples=10: Everything is a noise!\n",
      "eps=0.1, min_samples=20: Everything is a noise!\n",
      "eps=0.1, min_samples=30: Everything is a noise!\n",
      "eps=0.1, min_samples=40: Everything is a noise!\n",
      "eps=0.1, min_samples=50: Everything is a noise!\n",
      "eps=0.1, min_samples=60: Everything is a noise!\n",
      "eps=0.1, min_samples=70: Everything is a noise!\n",
      "eps=0.1, min_samples=80: Everything is a noise!\n",
      "eps=0.1, min_samples=90: Everything is a noise!\n",
      "eps=0.1, min_samples=100: Everything is a noise!\n",
      "eps=0.1, min_samples=110: Everything is a noise!\n",
      "eps=0.1, min_samples=120: Everything is a noise!\n",
      "eps=0.1, min_samples=130: Everything is a noise!\n",
      "eps=0.1, min_samples=140: Everything is a noise!\n",
      "eps=0.1, min_samples=150: Everything is a noise!\n",
      "eps=0.1, min_samples=160: Everything is a noise!\n",
      "eps=0.1, min_samples=170: Everything is a noise!\n",
      "eps=0.1, min_samples=180: Everything is a noise!\n",
      "eps=0.1, min_samples=190: Everything is a noise!\n",
      "eps=0.2, min_samples=10: -0.0065\n",
      "eps=0.2, min_samples=20: Everything is a noise!\n",
      "eps=0.2, min_samples=30: Everything is a noise!\n",
      "eps=0.2, min_samples=40: Everything is a noise!\n",
      "eps=0.2, min_samples=50: Everything is a noise!\n",
      "eps=0.2, min_samples=60: Everything is a noise!\n",
      "eps=0.2, min_samples=70: Everything is a noise!\n",
      "eps=0.2, min_samples=80: Everything is a noise!\n",
      "eps=0.2, min_samples=90: Everything is a noise!\n",
      "eps=0.2, min_samples=100: Everything is a noise!\n",
      "eps=0.2, min_samples=110: Everything is a noise!\n",
      "eps=0.2, min_samples=120: Everything is a noise!\n",
      "eps=0.2, min_samples=130: Everything is a noise!\n",
      "eps=0.2, min_samples=140: Everything is a noise!\n",
      "eps=0.2, min_samples=150: Everything is a noise!\n",
      "eps=0.2, min_samples=160: Everything is a noise!\n",
      "eps=0.2, min_samples=170: Everything is a noise!\n",
      "eps=0.2, min_samples=180: Everything is a noise!\n",
      "eps=0.2, min_samples=190: Everything is a noise!\n",
      "eps=0.3, min_samples=10: -0.1116\n",
      "eps=0.3, min_samples=20: Everything is a noise!\n",
      "eps=0.3, min_samples=30: Everything is a noise!\n",
      "eps=0.3, min_samples=40: Everything is a noise!\n",
      "eps=0.3, min_samples=50: Everything is a noise!\n",
      "eps=0.3, min_samples=60: Everything is a noise!\n",
      "eps=0.3, min_samples=70: Everything is a noise!\n",
      "eps=0.3, min_samples=80: Everything is a noise!\n",
      "eps=0.3, min_samples=90: Everything is a noise!\n",
      "eps=0.3, min_samples=100: Everything is a noise!\n",
      "eps=0.3, min_samples=110: Everything is a noise!\n",
      "eps=0.3, min_samples=120: Everything is a noise!\n",
      "eps=0.3, min_samples=130: Everything is a noise!\n",
      "eps=0.3, min_samples=140: Everything is a noise!\n",
      "eps=0.3, min_samples=150: Everything is a noise!\n",
      "eps=0.3, min_samples=160: Everything is a noise!\n",
      "eps=0.3, min_samples=170: Everything is a noise!\n",
      "eps=0.3, min_samples=180: Everything is a noise!\n",
      "eps=0.3, min_samples=190: Everything is a noise!\n",
      "eps=0.4, min_samples=10: 0.0274\n",
      "eps=0.4, min_samples=20: 0.004\n",
      "eps=0.4, min_samples=30: 0.0147\n",
      "eps=0.4, min_samples=40: 0.0121\n",
      "eps=0.4, min_samples=50: Everything is a noise!\n",
      "eps=0.4, min_samples=60: Everything is a noise!\n",
      "eps=0.4, min_samples=70: Everything is a noise!\n",
      "eps=0.4, min_samples=80: Everything is a noise!\n",
      "eps=0.4, min_samples=90: Everything is a noise!\n",
      "eps=0.4, min_samples=100: Everything is a noise!\n",
      "eps=0.4, min_samples=110: Everything is a noise!\n",
      "eps=0.4, min_samples=120: Everything is a noise!\n",
      "eps=0.4, min_samples=130: Everything is a noise!\n",
      "eps=0.4, min_samples=140: Everything is a noise!\n",
      "eps=0.4, min_samples=150: Everything is a noise!\n",
      "eps=0.4, min_samples=160: Everything is a noise!\n",
      "eps=0.4, min_samples=170: Everything is a noise!\n",
      "eps=0.4, min_samples=180: Everything is a noise!\n",
      "eps=0.4, min_samples=190: Everything is a noise!\n",
      "eps=0.5, min_samples=10: 0.0745\n",
      "eps=0.5, min_samples=20: 0.0571\n",
      "eps=0.5, min_samples=30: 0.0229\n",
      "eps=0.5, min_samples=40: -0.012\n",
      "eps=0.5, min_samples=50: 0.0298\n",
      "eps=0.5, min_samples=60: 0.0289\n",
      "eps=0.5, min_samples=70: Everything is a noise!\n",
      "eps=0.5, min_samples=80: Everything is a noise!\n",
      "eps=0.5, min_samples=90: Everything is a noise!\n",
      "eps=0.5, min_samples=100: Everything is a noise!\n",
      "eps=0.5, min_samples=110: Everything is a noise!\n",
      "eps=0.5, min_samples=120: Everything is a noise!\n",
      "eps=0.5, min_samples=130: Everything is a noise!\n",
      "eps=0.5, min_samples=140: Everything is a noise!\n",
      "eps=0.5, min_samples=150: Everything is a noise!\n",
      "eps=0.5, min_samples=160: Everything is a noise!\n",
      "eps=0.5, min_samples=170: Everything is a noise!\n",
      "eps=0.5, min_samples=180: Everything is a noise!\n",
      "eps=0.5, min_samples=190: Everything is a noise!\n",
      "eps=0.6, min_samples=10: 0.1006\n",
      "eps=0.6, min_samples=20: 0.0884\n",
      "eps=0.6, min_samples=30: 0.0708\n",
      "eps=0.6, min_samples=40: 0.0496\n",
      "eps=0.6, min_samples=50: 0.0473\n",
      "eps=0.6, min_samples=60: 0.0435\n",
      "eps=0.6, min_samples=70: 0.0429\n",
      "eps=0.6, min_samples=80: 0.0415\n",
      "eps=0.6, min_samples=90: 0.0058\n",
      "eps=0.6, min_samples=100: 0.0338\n",
      "eps=0.6, min_samples=110: Everything is a noise!\n",
      "eps=0.6, min_samples=120: Everything is a noise!\n",
      "eps=0.6, min_samples=130: Everything is a noise!\n",
      "eps=0.6, min_samples=140: Everything is a noise!\n",
      "eps=0.6, min_samples=150: Everything is a noise!\n",
      "eps=0.6, min_samples=160: Everything is a noise!\n",
      "eps=0.6, min_samples=170: Everything is a noise!\n",
      "eps=0.6, min_samples=180: Everything is a noise!\n",
      "eps=0.6, min_samples=190: Everything is a noise!\n",
      "eps=0.7, min_samples=10: 0.0621\n",
      "eps=0.7, min_samples=20: 0.0814\n",
      "eps=0.7, min_samples=30: 0.0932\n",
      "eps=0.7, min_samples=40: 0.0724\n",
      "eps=0.7, min_samples=50: 0.0718\n",
      "eps=0.7, min_samples=60: 0.0706\n",
      "eps=0.7, min_samples=70: 0.0681\n",
      "eps=0.7, min_samples=80: 0.0674\n",
      "eps=0.7, min_samples=90: 0.0668\n",
      "eps=0.7, min_samples=100: 0.0657\n",
      "eps=0.7, min_samples=110: 0.064\n",
      "eps=0.7, min_samples=120: 0.0597\n",
      "eps=0.7, min_samples=130: 0.0544\n",
      "eps=0.7, min_samples=140: 0.0325\n",
      "eps=0.7, min_samples=150: 0.0163\n",
      "eps=0.7, min_samples=160: Everything is a noise!\n",
      "eps=0.7, min_samples=170: Everything is a noise!\n",
      "eps=0.7, min_samples=180: Everything is a noise!\n",
      "eps=0.7, min_samples=190: Everything is a noise!\n",
      "eps=0.8, min_samples=10: 0.0858\n",
      "eps=0.8, min_samples=20: 0.0888\n",
      "eps=0.8, min_samples=30: 0.0809\n",
      "eps=0.8, min_samples=40: 0.085\n",
      "eps=0.8, min_samples=50: 0.0878\n",
      "eps=0.8, min_samples=60: 0.0875\n",
      "eps=0.8, min_samples=70: 0.0894\n",
      "eps=0.8, min_samples=80: 0.0894\n",
      "eps=0.8, min_samples=90: 0.0893\n",
      "eps=0.8, min_samples=100: 0.0882\n",
      "eps=0.8, min_samples=110: 0.0885\n",
      "eps=0.8, min_samples=120: 0.0881\n",
      "eps=0.8, min_samples=130: 0.0874\n",
      "eps=0.8, min_samples=140: 0.0861\n",
      "eps=0.8, min_samples=150: 0.0838\n",
      "eps=0.8, min_samples=160: 0.0824\n",
      "eps=0.8, min_samples=170: 0.0804\n",
      "eps=0.8, min_samples=180: 0.0774\n",
      "eps=0.8, min_samples=190: 0.0745\n",
      "eps=0.9, min_samples=10: 0.0836\n",
      "eps=0.9, min_samples=20: 0.0867\n",
      "eps=0.9, min_samples=30: 0.0997\n",
      "eps=0.9, min_samples=40: 0.0943\n",
      "eps=0.9, min_samples=50: 0.0961\n",
      "eps=0.9, min_samples=60: 0.0964\n",
      "eps=0.9, min_samples=70: 0.096\n",
      "eps=0.9, min_samples=80: 0.0962\n",
      "eps=0.9, min_samples=90: 0.0956\n",
      "eps=0.9, min_samples=100: 0.096\n",
      "eps=0.9, min_samples=110: 0.096\n",
      "eps=0.9, min_samples=120: 0.096\n",
      "eps=0.9, min_samples=130: 0.0957\n",
      "eps=0.9, min_samples=140: 0.0953\n",
      "eps=0.9, min_samples=150: 0.095\n",
      "eps=0.9, min_samples=160: 0.0943\n",
      "eps=0.9, min_samples=170: 0.0943\n",
      "eps=0.9, min_samples=180: 0.0963\n",
      "eps=0.9, min_samples=190: 0.0963\n",
      "eps=1.0, min_samples=10: 0.0923\n",
      "eps=1.0, min_samples=20: 0.093\n",
      "eps=1.0, min_samples=30: 0.0952\n",
      "eps=1.0, min_samples=40: 0.0962\n",
      "eps=1.0, min_samples=50: 0.0965\n",
      "eps=1.0, min_samples=60: 0.0962\n",
      "eps=1.0, min_samples=70: 0.0974\n",
      "eps=1.0, min_samples=80: 0.0978\n",
      "eps=1.0, min_samples=90: 0.1001\n",
      "eps=1.0, min_samples=100: 0.0987\n",
      "eps=1.0, min_samples=110: 0.0995\n",
      "eps=1.0, min_samples=120: 0.0998\n",
      "eps=1.0, min_samples=130: 0.0996\n",
      "eps=1.0, min_samples=140: 0.0994\n",
      "eps=1.0, min_samples=150: 0.0997\n",
      "eps=1.0, min_samples=160: 0.0999\n",
      "eps=1.0, min_samples=170: 0.1\n",
      "eps=1.0, min_samples=180: 0.1002\n",
      "eps=1.0, min_samples=190: 0.0998\n"
     ]
    }
   ],
   "source": [
    "range_eps = np.linspace(start=0.1, stop=1.0, num=10)\n",
    "range_min_samples = range(10, 200, 10)\n",
    "\n",
    "\n",
    "def dbscan_gridsearch(X, range_eps, range_min_samples):\n",
    "    search_results = []\n",
    "    for i in range_eps:\n",
    "        for j in range_min_samples:\n",
    "            clustering = DBSCAN(eps=i, min_samples=j).fit(X)\n",
    "            cluster_labels = clustering.labels_\n",
    "\n",
    "            if len(np.unique(cluster_labels))==1:\n",
    "                print(\"eps=\" + str(round(i, 2)) + \", min_samples=\" + str(j)  \n",
    "                      + \": Everything is a noise!\")\n",
    "            else:\n",
    "                silhouette_avg = silhouette_score(X_clean, cluster_labels)\n",
    "                print(\"eps=\" + str(round(i, 2)) + \", min_samples=\" + str(j) +\": \" \n",
    "                      + str(round(silhouette_avg, 4)))\n",
    "                search_results.append(((i, j), silhouette_avg))\n",
    "\n",
    "    return sorted(search_results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "search_results = dbscan_gridsearch(X_clean, range_eps, range_min_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "ee8a825c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0.6, 10), 0.10062334395122446),\n",
       " ((1.0, 180), 0.10019600298927343),\n",
       " ((1.0, 90), 0.10008703778391964),\n",
       " ((1.0, 170), 0.09996879475275447),\n",
       " ((1.0, 160), 0.09994635643362708),\n",
       " ((1.0, 190), 0.099843383104516),\n",
       " ((1.0, 120), 0.09975458237952906),\n",
       " ((1.0, 150), 0.09968969400558335),\n",
       " ((0.9, 30), 0.09966479716754044),\n",
       " ((1.0, 130), 0.09957527231470707),\n",
       " ((1.0, 110), 0.09945751277936156),\n",
       " ((1.0, 140), 0.09940835589336891),\n",
       " ((1.0, 100), 0.09867890593139018),\n",
       " ((1.0, 80), 0.09777008789765693),\n",
       " ((1.0, 70), 0.09736258993747669),\n",
       " ((1.0, 50), 0.0965156529388127),\n",
       " ((0.9, 60), 0.09642652017197094),\n",
       " ((0.9, 190), 0.09629273988643941),\n",
       " ((0.9, 180), 0.09625210701405415),\n",
       " ((0.9, 80), 0.09624053687037468),\n",
       " ((1.0, 40), 0.09623713712167237),\n",
       " ((1.0, 60), 0.09615374573902442),\n",
       " ((0.9, 50), 0.09614604537402098),\n",
       " ((0.9, 100), 0.09604364933028252),\n",
       " ((0.9, 70), 0.09601265971793706),\n",
       " ((0.9, 110), 0.0959877864207942),\n",
       " ((0.9, 120), 0.0959877864207942),\n",
       " ((0.9, 130), 0.09568807086067671),\n",
       " ((0.9, 90), 0.09558881716396911),\n",
       " ((0.9, 140), 0.09528522336695115),\n",
       " ((1.0, 30), 0.09522166192796085),\n",
       " ((0.9, 150), 0.09503497211369637),\n",
       " ((0.9, 160), 0.0943294775527959),\n",
       " ((0.9, 170), 0.09431104914239828),\n",
       " ((0.9, 40), 0.09425259628553623),\n",
       " ((0.7000000000000001, 30), 0.09316984145452059),\n",
       " ((1.0, 20), 0.09302338428730225),\n",
       " ((1.0, 10), 0.09233013108149128),\n",
       " ((0.8, 70), 0.0894383882122932),\n",
       " ((0.8, 80), 0.0894383882122932),\n",
       " ((0.8, 90), 0.08925748559910748),\n",
       " ((0.8, 20), 0.0887984125995101),\n",
       " ((0.8, 110), 0.08852429123141344),\n",
       " ((0.6, 20), 0.0884427665184617),\n",
       " ((0.8, 100), 0.08816785728402195),\n",
       " ((0.8, 120), 0.08812998361683541),\n",
       " ((0.8, 50), 0.08783809720135012),\n",
       " ((0.8, 60), 0.087516093844652),\n",
       " ((0.8, 130), 0.08743258086719122),\n",
       " ((0.9, 20), 0.08671854304898358),\n",
       " ((0.8, 140), 0.08611593113537899),\n",
       " ((0.8, 10), 0.08580494567198423),\n",
       " ((0.8, 40), 0.08500632042546427),\n",
       " ((0.8, 150), 0.08377898456393858),\n",
       " ((0.9, 10), 0.08364157872797186),\n",
       " ((0.8, 160), 0.08237978194902354),\n",
       " ((0.7000000000000001, 20), 0.08143245834278721),\n",
       " ((0.8, 30), 0.08090847673021784),\n",
       " ((0.8, 170), 0.08042893778744142),\n",
       " ((0.8, 180), 0.07736597071942786),\n",
       " ((0.8, 190), 0.0745449913892438),\n",
       " ((0.5, 10), 0.07450913693659045),\n",
       " ((0.7000000000000001, 40), 0.07242905511483597),\n",
       " ((0.7000000000000001, 50), 0.07175719268446591),\n",
       " ((0.6, 30), 0.0708165334448621),\n",
       " ((0.7000000000000001, 60), 0.07057925785039873),\n",
       " ((0.7000000000000001, 70), 0.0681160626907938),\n",
       " ((0.7000000000000001, 80), 0.06741546562545431),\n",
       " ((0.7000000000000001, 90), 0.0668495409033933),\n",
       " ((0.7000000000000001, 100), 0.0656993480796814),\n",
       " ((0.7000000000000001, 110), 0.06401415558005957),\n",
       " ((0.7000000000000001, 10), 0.06209544850147582),\n",
       " ((0.7000000000000001, 120), 0.05971430948199135),\n",
       " ((0.5, 20), 0.05706958932630636),\n",
       " ((0.7000000000000001, 130), 0.05436852094063774),\n",
       " ((0.6, 40), 0.049610092397126875),\n",
       " ((0.6, 50), 0.047275583548978775),\n",
       " ((0.6, 60), 0.043461580431662844),\n",
       " ((0.6, 70), 0.04292896398138327),\n",
       " ((0.6, 80), 0.041480747213307224),\n",
       " ((0.6, 100), 0.03378010368857992),\n",
       " ((0.7000000000000001, 140), 0.032526636219244176),\n",
       " ((0.5, 50), 0.02979400561983962),\n",
       " ((0.5, 60), 0.02892983015133575),\n",
       " ((0.4, 10), 0.027426074024788145),\n",
       " ((0.5, 30), 0.022949286539875532),\n",
       " ((0.7000000000000001, 150), 0.016312563672737944),\n",
       " ((0.4, 30), 0.014656130401514192),\n",
       " ((0.4, 40), 0.012087344073204633),\n",
       " ((0.6, 90), 0.005820626625563744),\n",
       " ((0.4, 20), 0.004003411838789628),\n",
       " ((0.2, 10), -0.00651389697387488),\n",
       " ((0.5, 40), -0.011991889562644756),\n",
       " ((0.30000000000000004, 10), -0.1115815565893576)]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525cb6e3",
   "metadata": {},
   "source": [
    "Looks like the winner is: `eps=0.6, min_samples=10`\n",
    "\n",
    "Now that we have a working grid search of sorts, let's try working on the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0006a02",
   "metadata": {},
   "source": [
    "# Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "8072015d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the list of file paths in gcs \n",
    "len(keys[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "d80f8ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(987, 1)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "b341e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing=[]\n",
    "X_hold = [] \n",
    "protein_name_hold = []\n",
    "\n",
    "for key in keys[1:]:\n",
    "    # Loop through all 24 DeepFold embedding files\n",
    "    \n",
    "    # I actually only need the file path once in the right storage.\n",
    "    key = gcs.uri_to_bucket_and_key(key)[1]\n",
    "    \n",
    "    # Download, decode, and split into list. Ignore first 3 items.\n",
    "    df_emb = gcs.download_text(key)\\\n",
    "             .decode('utf-8').split(\",\")[3:]\n",
    "    \n",
    "    n_proteins = int((len(df_emb))/2)\n",
    "    \n",
    "    # Take as np array and reshape\n",
    "    np_emb = np.array(df_emb).reshape(n_proteins, 2)\n",
    "    \n",
    "    # Now take the embeddings and protein names separately. \n",
    "    X=np_emb[:,1].reshape(n_proteins,1)\n",
    "    protein=np_emb[:,0].reshape(n_proteins,1)\n",
    "    \n",
    "    # Parse the values of embeddings\n",
    "    parsed_list = list(map(parse_deepfold_embedding, X))\n",
    "    \n",
    "    # Identify proteins where the DeepFold embeddings could not be generated\n",
    "    for i in range(len(parsed_list)):\n",
    "        if len(parsed_list[i])!= 398:\n",
    "            missing.append(i)\n",
    "    \n",
    "    # Take the remainder and stack.\n",
    "    X_clean = np.stack([x for i,x in enumerate(parsed_list) if i not in missing])\n",
    "    protein_clean =  np.stack([x for i,x in enumerate(protein) if i not in missing])\n",
    "    \n",
    "    X_hold.append(X_clean)\n",
    "    protein_name_hold.append(protein_clean)\n",
    "    \n",
    "X_full = np.vstack(X_hold)\n",
    "protein_name_full = np.vstack(protein_name_hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "b6ed04b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20485, 398)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "2a44285a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20485, 1)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_name_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "dedfe6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7f343",
   "metadata": {},
   "source": [
    "## Cluster full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "f40353a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20485, 20485)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = euclidean_distances(X_full, X_full)\n",
    "ed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "7f4dcf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.4139664121859254 1.1267737285441222\n"
     ]
    }
   ],
   "source": [
    "min_ed = np.min(ed)\n",
    "max_ed = np.max(ed)\n",
    "median_ed = np.median(ed)\n",
    "\n",
    "print(min_ed, max_ed, median_ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "588765ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps=0.01, min_samples=10: Everything is a noise!\n",
      "eps=0.01, min_samples=20: Everything is a noise!\n",
      "eps=0.01, min_samples=30: Everything is a noise!\n",
      "eps=0.01, min_samples=40: Everything is a noise!\n",
      "eps=0.01, min_samples=50: Everything is a noise!\n",
      "eps=0.01, min_samples=60: Everything is a noise!\n",
      "eps=0.01, min_samples=70: Everything is a noise!\n",
      "eps=0.01, min_samples=80: Everything is a noise!\n",
      "eps=0.01, min_samples=90: Everything is a noise!\n",
      "eps=0.01, min_samples=100: Everything is a noise!\n",
      "eps=0.01, min_samples=110: Everything is a noise!\n",
      "eps=0.01, min_samples=120: Everything is a noise!\n",
      "eps=0.01, min_samples=130: Everything is a noise!\n",
      "eps=0.01, min_samples=140: Everything is a noise!\n",
      "eps=0.01, min_samples=150: Everything is a noise!\n",
      "eps=0.01, min_samples=160: Everything is a noise!\n",
      "eps=0.01, min_samples=170: Everything is a noise!\n",
      "eps=0.01, min_samples=180: Everything is a noise!\n",
      "eps=0.01, min_samples=190: Everything is a noise!\n",
      "eps=0.01, min_samples=200: Everything is a noise!\n",
      "eps=0.01, min_samples=210: Everything is a noise!\n",
      "eps=0.01, min_samples=220: Everything is a noise!\n",
      "eps=0.01, min_samples=230: Everything is a noise!\n",
      "eps=0.01, min_samples=240: Everything is a noise!\n",
      "eps=0.01, min_samples=250: Everything is a noise!\n",
      "eps=0.01, min_samples=260: Everything is a noise!\n",
      "eps=0.01, min_samples=270: Everything is a noise!\n",
      "eps=0.01, min_samples=280: Everything is a noise!\n",
      "eps=0.01, min_samples=290: Everything is a noise!\n",
      "eps=0.01, min_samples=300: Everything is a noise!\n",
      "eps=0.01, min_samples=310: Everything is a noise!\n",
      "eps=0.01, min_samples=320: Everything is a noise!\n",
      "eps=0.01, min_samples=330: Everything is a noise!\n",
      "eps=0.01, min_samples=340: Everything is a noise!\n",
      "eps=0.01, min_samples=350: Everything is a noise!\n",
      "eps=0.01, min_samples=360: Everything is a noise!\n",
      "eps=0.01, min_samples=370: Everything is a noise!\n",
      "eps=0.01, min_samples=380: Everything is a noise!\n",
      "eps=0.01, min_samples=390: Everything is a noise!\n",
      "eps=0.01, min_samples=400: Everything is a noise!\n",
      "eps=0.01, min_samples=410: Everything is a noise!\n",
      "eps=0.01, min_samples=420: Everything is a noise!\n",
      "eps=0.01, min_samples=430: Everything is a noise!\n",
      "eps=0.01, min_samples=440: Everything is a noise!\n",
      "eps=0.01, min_samples=450: Everything is a noise!\n",
      "eps=0.01, min_samples=460: Everything is a noise!\n",
      "eps=0.01, min_samples=470: Everything is a noise!\n",
      "eps=0.01, min_samples=480: Everything is a noise!\n",
      "eps=0.01, min_samples=490: Everything is a noise!\n",
      "eps=0.03, min_samples=10: Everything is a noise!\n",
      "eps=0.03, min_samples=20: Everything is a noise!\n",
      "eps=0.03, min_samples=30: Everything is a noise!\n",
      "eps=0.03, min_samples=40: Everything is a noise!\n",
      "eps=0.03, min_samples=50: Everything is a noise!\n",
      "eps=0.03, min_samples=60: Everything is a noise!\n",
      "eps=0.03, min_samples=70: Everything is a noise!\n",
      "eps=0.03, min_samples=80: Everything is a noise!\n",
      "eps=0.03, min_samples=90: Everything is a noise!\n",
      "eps=0.03, min_samples=100: Everything is a noise!\n",
      "eps=0.03, min_samples=110: Everything is a noise!\n",
      "eps=0.03, min_samples=120: Everything is a noise!\n",
      "eps=0.03, min_samples=130: Everything is a noise!\n",
      "eps=0.03, min_samples=140: Everything is a noise!\n",
      "eps=0.03, min_samples=150: Everything is a noise!\n",
      "eps=0.03, min_samples=160: Everything is a noise!\n",
      "eps=0.03, min_samples=170: Everything is a noise!\n",
      "eps=0.03, min_samples=180: Everything is a noise!\n",
      "eps=0.03, min_samples=190: Everything is a noise!\n",
      "eps=0.03, min_samples=200: Everything is a noise!\n",
      "eps=0.03, min_samples=210: Everything is a noise!\n",
      "eps=0.03, min_samples=220: Everything is a noise!\n",
      "eps=0.03, min_samples=230: Everything is a noise!\n",
      "eps=0.03, min_samples=240: Everything is a noise!\n",
      "eps=0.03, min_samples=250: Everything is a noise!\n",
      "eps=0.03, min_samples=260: Everything is a noise!\n",
      "eps=0.03, min_samples=270: Everything is a noise!\n",
      "eps=0.03, min_samples=280: Everything is a noise!\n",
      "eps=0.03, min_samples=290: Everything is a noise!\n",
      "eps=0.03, min_samples=300: Everything is a noise!\n",
      "eps=0.03, min_samples=310: Everything is a noise!\n",
      "eps=0.03, min_samples=320: Everything is a noise!\n",
      "eps=0.03, min_samples=330: Everything is a noise!\n",
      "eps=0.03, min_samples=340: Everything is a noise!\n",
      "eps=0.03, min_samples=350: Everything is a noise!\n",
      "eps=0.03, min_samples=360: Everything is a noise!\n",
      "eps=0.03, min_samples=370: Everything is a noise!\n",
      "eps=0.03, min_samples=380: Everything is a noise!\n",
      "eps=0.03, min_samples=390: Everything is a noise!\n",
      "eps=0.03, min_samples=400: Everything is a noise!\n",
      "eps=0.03, min_samples=410: Everything is a noise!\n",
      "eps=0.03, min_samples=420: Everything is a noise!\n",
      "eps=0.03, min_samples=430: Everything is a noise!\n",
      "eps=0.03, min_samples=440: Everything is a noise!\n",
      "eps=0.03, min_samples=450: Everything is a noise!\n",
      "eps=0.03, min_samples=460: Everything is a noise!\n",
      "eps=0.03, min_samples=470: Everything is a noise!\n",
      "eps=0.03, min_samples=480: Everything is a noise!\n",
      "eps=0.03, min_samples=490: Everything is a noise!\n",
      "eps=0.05, min_samples=10: Everything is a noise!\n",
      "eps=0.05, min_samples=20: Everything is a noise!\n",
      "eps=0.05, min_samples=30: Everything is a noise!\n",
      "eps=0.05, min_samples=40: Everything is a noise!\n",
      "eps=0.05, min_samples=50: Everything is a noise!\n",
      "eps=0.05, min_samples=60: Everything is a noise!\n",
      "eps=0.05, min_samples=70: Everything is a noise!\n",
      "eps=0.05, min_samples=80: Everything is a noise!\n",
      "eps=0.05, min_samples=90: Everything is a noise!\n",
      "eps=0.05, min_samples=100: Everything is a noise!\n",
      "eps=0.05, min_samples=110: Everything is a noise!\n",
      "eps=0.05, min_samples=120: Everything is a noise!\n",
      "eps=0.05, min_samples=130: Everything is a noise!\n",
      "eps=0.05, min_samples=140: Everything is a noise!\n",
      "eps=0.05, min_samples=150: Everything is a noise!\n",
      "eps=0.05, min_samples=160: Everything is a noise!\n",
      "eps=0.05, min_samples=170: Everything is a noise!\n",
      "eps=0.05, min_samples=180: Everything is a noise!\n",
      "eps=0.05, min_samples=190: Everything is a noise!\n",
      "eps=0.05, min_samples=200: Everything is a noise!\n",
      "eps=0.05, min_samples=210: Everything is a noise!\n",
      "eps=0.05, min_samples=220: Everything is a noise!\n",
      "eps=0.05, min_samples=230: Everything is a noise!\n",
      "eps=0.05, min_samples=240: Everything is a noise!\n",
      "eps=0.05, min_samples=250: Everything is a noise!\n",
      "eps=0.05, min_samples=260: Everything is a noise!\n",
      "eps=0.05, min_samples=270: Everything is a noise!\n",
      "eps=0.05, min_samples=280: Everything is a noise!\n",
      "eps=0.05, min_samples=290: Everything is a noise!\n",
      "eps=0.05, min_samples=300: Everything is a noise!\n",
      "eps=0.05, min_samples=310: Everything is a noise!\n",
      "eps=0.05, min_samples=320: Everything is a noise!\n",
      "eps=0.05, min_samples=330: Everything is a noise!\n",
      "eps=0.05, min_samples=340: Everything is a noise!\n",
      "eps=0.05, min_samples=350: Everything is a noise!\n",
      "eps=0.05, min_samples=360: Everything is a noise!\n",
      "eps=0.05, min_samples=370: Everything is a noise!\n",
      "eps=0.05, min_samples=380: Everything is a noise!\n",
      "eps=0.05, min_samples=390: Everything is a noise!\n",
      "eps=0.05, min_samples=400: Everything is a noise!\n",
      "eps=0.05, min_samples=410: Everything is a noise!\n",
      "eps=0.05, min_samples=420: Everything is a noise!\n",
      "eps=0.05, min_samples=430: Everything is a noise!\n",
      "eps=0.05, min_samples=440: Everything is a noise!\n",
      "eps=0.05, min_samples=450: Everything is a noise!\n",
      "eps=0.05, min_samples=460: Everything is a noise!\n",
      "eps=0.05, min_samples=470: Everything is a noise!\n",
      "eps=0.05, min_samples=480: Everything is a noise!\n",
      "eps=0.05, min_samples=490: Everything is a noise!\n",
      "eps=0.07, min_samples=10: -0.0689\n",
      "eps=0.07, min_samples=20: Everything is a noise!\n",
      "eps=0.07, min_samples=30: Everything is a noise!\n",
      "eps=0.07, min_samples=40: Everything is a noise!\n",
      "eps=0.07, min_samples=50: Everything is a noise!\n",
      "eps=0.07, min_samples=60: Everything is a noise!\n",
      "eps=0.07, min_samples=70: Everything is a noise!\n",
      "eps=0.07, min_samples=80: Everything is a noise!\n",
      "eps=0.07, min_samples=90: Everything is a noise!\n",
      "eps=0.07, min_samples=100: Everything is a noise!\n",
      "eps=0.07, min_samples=110: Everything is a noise!\n",
      "eps=0.07, min_samples=120: Everything is a noise!\n",
      "eps=0.07, min_samples=130: Everything is a noise!\n",
      "eps=0.07, min_samples=140: Everything is a noise!\n",
      "eps=0.07, min_samples=150: Everything is a noise!\n",
      "eps=0.07, min_samples=160: Everything is a noise!\n",
      "eps=0.07, min_samples=170: Everything is a noise!\n",
      "eps=0.07, min_samples=180: Everything is a noise!\n",
      "eps=0.07, min_samples=190: Everything is a noise!\n",
      "eps=0.07, min_samples=200: Everything is a noise!\n",
      "eps=0.07, min_samples=210: Everything is a noise!\n",
      "eps=0.07, min_samples=220: Everything is a noise!\n",
      "eps=0.07, min_samples=230: Everything is a noise!\n",
      "eps=0.07, min_samples=240: Everything is a noise!\n",
      "eps=0.07, min_samples=250: Everything is a noise!\n",
      "eps=0.07, min_samples=260: Everything is a noise!\n",
      "eps=0.07, min_samples=270: Everything is a noise!\n",
      "eps=0.07, min_samples=280: Everything is a noise!\n",
      "eps=0.07, min_samples=290: Everything is a noise!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps=0.07, min_samples=300: Everything is a noise!\n",
      "eps=0.07, min_samples=310: Everything is a noise!\n",
      "eps=0.07, min_samples=320: Everything is a noise!\n",
      "eps=0.07, min_samples=330: Everything is a noise!\n",
      "eps=0.07, min_samples=340: Everything is a noise!\n",
      "eps=0.07, min_samples=350: Everything is a noise!\n",
      "eps=0.07, min_samples=360: Everything is a noise!\n",
      "eps=0.07, min_samples=370: Everything is a noise!\n",
      "eps=0.07, min_samples=380: Everything is a noise!\n",
      "eps=0.07, min_samples=390: Everything is a noise!\n",
      "eps=0.07, min_samples=400: Everything is a noise!\n",
      "eps=0.07, min_samples=410: Everything is a noise!\n",
      "eps=0.07, min_samples=420: Everything is a noise!\n",
      "eps=0.07, min_samples=430: Everything is a noise!\n",
      "eps=0.07, min_samples=440: Everything is a noise!\n",
      "eps=0.07, min_samples=450: Everything is a noise!\n",
      "eps=0.07, min_samples=460: Everything is a noise!\n",
      "eps=0.07, min_samples=470: Everything is a noise!\n",
      "eps=0.07, min_samples=480: Everything is a noise!\n",
      "eps=0.07, min_samples=490: Everything is a noise!\n",
      "eps=0.09, min_samples=10: -0.0561\n",
      "eps=0.09, min_samples=20: Everything is a noise!\n",
      "eps=0.09, min_samples=30: Everything is a noise!\n",
      "eps=0.09, min_samples=40: Everything is a noise!\n",
      "eps=0.09, min_samples=50: Everything is a noise!\n",
      "eps=0.09, min_samples=60: Everything is a noise!\n",
      "eps=0.09, min_samples=70: Everything is a noise!\n",
      "eps=0.09, min_samples=80: Everything is a noise!\n",
      "eps=0.09, min_samples=90: Everything is a noise!\n",
      "eps=0.09, min_samples=100: Everything is a noise!\n",
      "eps=0.09, min_samples=110: Everything is a noise!\n",
      "eps=0.09, min_samples=120: Everything is a noise!\n",
      "eps=0.09, min_samples=130: Everything is a noise!\n",
      "eps=0.09, min_samples=140: Everything is a noise!\n",
      "eps=0.09, min_samples=150: Everything is a noise!\n",
      "eps=0.09, min_samples=160: Everything is a noise!\n",
      "eps=0.09, min_samples=170: Everything is a noise!\n",
      "eps=0.09, min_samples=180: Everything is a noise!\n",
      "eps=0.09, min_samples=190: Everything is a noise!\n",
      "eps=0.09, min_samples=200: Everything is a noise!\n",
      "eps=0.09, min_samples=210: Everything is a noise!\n",
      "eps=0.09, min_samples=220: Everything is a noise!\n",
      "eps=0.09, min_samples=230: Everything is a noise!\n",
      "eps=0.09, min_samples=240: Everything is a noise!\n",
      "eps=0.09, min_samples=250: Everything is a noise!\n",
      "eps=0.09, min_samples=260: Everything is a noise!\n",
      "eps=0.09, min_samples=270: Everything is a noise!\n",
      "eps=0.09, min_samples=280: Everything is a noise!\n",
      "eps=0.09, min_samples=290: Everything is a noise!\n",
      "eps=0.09, min_samples=300: Everything is a noise!\n",
      "eps=0.09, min_samples=310: Everything is a noise!\n",
      "eps=0.09, min_samples=320: Everything is a noise!\n",
      "eps=0.09, min_samples=330: Everything is a noise!\n",
      "eps=0.09, min_samples=340: Everything is a noise!\n",
      "eps=0.09, min_samples=350: Everything is a noise!\n",
      "eps=0.09, min_samples=360: Everything is a noise!\n",
      "eps=0.09, min_samples=370: Everything is a noise!\n",
      "eps=0.09, min_samples=380: Everything is a noise!\n",
      "eps=0.09, min_samples=390: Everything is a noise!\n",
      "eps=0.09, min_samples=400: Everything is a noise!\n",
      "eps=0.09, min_samples=410: Everything is a noise!\n",
      "eps=0.09, min_samples=420: Everything is a noise!\n",
      "eps=0.09, min_samples=430: Everything is a noise!\n",
      "eps=0.09, min_samples=440: Everything is a noise!\n",
      "eps=0.09, min_samples=450: Everything is a noise!\n",
      "eps=0.09, min_samples=460: Everything is a noise!\n",
      "eps=0.09, min_samples=470: Everything is a noise!\n",
      "eps=0.09, min_samples=480: Everything is a noise!\n",
      "eps=0.09, min_samples=490: Everything is a noise!\n",
      "eps=0.12, min_samples=10: -0.0522\n",
      "eps=0.12, min_samples=20: -0.0547\n",
      "eps=0.12, min_samples=30: Everything is a noise!\n",
      "eps=0.12, min_samples=40: Everything is a noise!\n",
      "eps=0.12, min_samples=50: Everything is a noise!\n",
      "eps=0.12, min_samples=60: Everything is a noise!\n",
      "eps=0.12, min_samples=70: Everything is a noise!\n",
      "eps=0.12, min_samples=80: Everything is a noise!\n",
      "eps=0.12, min_samples=90: Everything is a noise!\n",
      "eps=0.12, min_samples=100: Everything is a noise!\n",
      "eps=0.12, min_samples=110: Everything is a noise!\n",
      "eps=0.12, min_samples=120: Everything is a noise!\n",
      "eps=0.12, min_samples=130: Everything is a noise!\n",
      "eps=0.12, min_samples=140: Everything is a noise!\n",
      "eps=0.12, min_samples=150: Everything is a noise!\n",
      "eps=0.12, min_samples=160: Everything is a noise!\n",
      "eps=0.12, min_samples=170: Everything is a noise!\n",
      "eps=0.12, min_samples=180: Everything is a noise!\n",
      "eps=0.12, min_samples=190: Everything is a noise!\n",
      "eps=0.12, min_samples=200: Everything is a noise!\n",
      "eps=0.12, min_samples=210: Everything is a noise!\n",
      "eps=0.12, min_samples=220: Everything is a noise!\n",
      "eps=0.12, min_samples=230: Everything is a noise!\n",
      "eps=0.12, min_samples=240: Everything is a noise!\n",
      "eps=0.12, min_samples=250: Everything is a noise!\n",
      "eps=0.12, min_samples=260: Everything is a noise!\n",
      "eps=0.12, min_samples=270: Everything is a noise!\n",
      "eps=0.12, min_samples=280: Everything is a noise!\n",
      "eps=0.12, min_samples=290: Everything is a noise!\n",
      "eps=0.12, min_samples=300: Everything is a noise!\n",
      "eps=0.12, min_samples=310: Everything is a noise!\n",
      "eps=0.12, min_samples=320: Everything is a noise!\n",
      "eps=0.12, min_samples=330: Everything is a noise!\n",
      "eps=0.12, min_samples=340: Everything is a noise!\n",
      "eps=0.12, min_samples=350: Everything is a noise!\n",
      "eps=0.12, min_samples=360: Everything is a noise!\n",
      "eps=0.12, min_samples=370: Everything is a noise!\n",
      "eps=0.12, min_samples=380: Everything is a noise!\n",
      "eps=0.12, min_samples=390: Everything is a noise!\n",
      "eps=0.12, min_samples=400: Everything is a noise!\n",
      "eps=0.12, min_samples=410: Everything is a noise!\n",
      "eps=0.12, min_samples=420: Everything is a noise!\n",
      "eps=0.12, min_samples=430: Everything is a noise!\n",
      "eps=0.12, min_samples=440: Everything is a noise!\n",
      "eps=0.12, min_samples=450: Everything is a noise!\n",
      "eps=0.12, min_samples=460: Everything is a noise!\n",
      "eps=0.12, min_samples=470: Everything is a noise!\n",
      "eps=0.12, min_samples=480: Everything is a noise!\n",
      "eps=0.12, min_samples=490: Everything is a noise!\n",
      "eps=0.14, min_samples=10: -0.0614\n",
      "eps=0.14, min_samples=20: -0.0488\n",
      "eps=0.14, min_samples=30: Everything is a noise!\n",
      "eps=0.14, min_samples=40: Everything is a noise!\n",
      "eps=0.14, min_samples=50: Everything is a noise!\n",
      "eps=0.14, min_samples=60: Everything is a noise!\n",
      "eps=0.14, min_samples=70: Everything is a noise!\n",
      "eps=0.14, min_samples=80: Everything is a noise!\n",
      "eps=0.14, min_samples=90: Everything is a noise!\n",
      "eps=0.14, min_samples=100: Everything is a noise!\n",
      "eps=0.14, min_samples=110: Everything is a noise!\n",
      "eps=0.14, min_samples=120: Everything is a noise!\n",
      "eps=0.14, min_samples=130: Everything is a noise!\n",
      "eps=0.14, min_samples=140: Everything is a noise!\n",
      "eps=0.14, min_samples=150: Everything is a noise!\n",
      "eps=0.14, min_samples=160: Everything is a noise!\n",
      "eps=0.14, min_samples=170: Everything is a noise!\n",
      "eps=0.14, min_samples=180: Everything is a noise!\n",
      "eps=0.14, min_samples=190: Everything is a noise!\n",
      "eps=0.14, min_samples=200: Everything is a noise!\n",
      "eps=0.14, min_samples=210: Everything is a noise!\n",
      "eps=0.14, min_samples=220: Everything is a noise!\n",
      "eps=0.14, min_samples=230: Everything is a noise!\n",
      "eps=0.14, min_samples=240: Everything is a noise!\n",
      "eps=0.14, min_samples=250: Everything is a noise!\n",
      "eps=0.14, min_samples=260: Everything is a noise!\n",
      "eps=0.14, min_samples=270: Everything is a noise!\n",
      "eps=0.14, min_samples=280: Everything is a noise!\n",
      "eps=0.14, min_samples=290: Everything is a noise!\n",
      "eps=0.14, min_samples=300: Everything is a noise!\n",
      "eps=0.14, min_samples=310: Everything is a noise!\n",
      "eps=0.14, min_samples=320: Everything is a noise!\n",
      "eps=0.14, min_samples=330: Everything is a noise!\n",
      "eps=0.14, min_samples=340: Everything is a noise!\n",
      "eps=0.14, min_samples=350: Everything is a noise!\n",
      "eps=0.14, min_samples=360: Everything is a noise!\n",
      "eps=0.14, min_samples=370: Everything is a noise!\n",
      "eps=0.14, min_samples=380: Everything is a noise!\n",
      "eps=0.14, min_samples=390: Everything is a noise!\n",
      "eps=0.14, min_samples=400: Everything is a noise!\n",
      "eps=0.14, min_samples=410: Everything is a noise!\n",
      "eps=0.14, min_samples=420: Everything is a noise!\n",
      "eps=0.14, min_samples=430: Everything is a noise!\n",
      "eps=0.14, min_samples=440: Everything is a noise!\n",
      "eps=0.14, min_samples=450: Everything is a noise!\n",
      "eps=0.14, min_samples=460: Everything is a noise!\n",
      "eps=0.14, min_samples=470: Everything is a noise!\n",
      "eps=0.14, min_samples=480: Everything is a noise!\n",
      "eps=0.14, min_samples=490: Everything is a noise!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps=0.16, min_samples=10: -0.0574\n",
      "eps=0.16, min_samples=20: -0.0423\n",
      "eps=0.16, min_samples=30: Everything is a noise!\n",
      "eps=0.16, min_samples=40: Everything is a noise!\n",
      "eps=0.16, min_samples=50: Everything is a noise!\n",
      "eps=0.16, min_samples=60: Everything is a noise!\n",
      "eps=0.16, min_samples=70: Everything is a noise!\n",
      "eps=0.16, min_samples=80: Everything is a noise!\n",
      "eps=0.16, min_samples=90: Everything is a noise!\n",
      "eps=0.16, min_samples=100: Everything is a noise!\n",
      "eps=0.16, min_samples=110: Everything is a noise!\n",
      "eps=0.16, min_samples=120: Everything is a noise!\n",
      "eps=0.16, min_samples=130: Everything is a noise!\n",
      "eps=0.16, min_samples=140: Everything is a noise!\n",
      "eps=0.16, min_samples=150: Everything is a noise!\n",
      "eps=0.16, min_samples=160: Everything is a noise!\n",
      "eps=0.16, min_samples=170: Everything is a noise!\n",
      "eps=0.16, min_samples=180: Everything is a noise!\n",
      "eps=0.16, min_samples=190: Everything is a noise!\n",
      "eps=0.16, min_samples=200: Everything is a noise!\n",
      "eps=0.16, min_samples=210: Everything is a noise!\n",
      "eps=0.16, min_samples=220: Everything is a noise!\n",
      "eps=0.16, min_samples=230: Everything is a noise!\n",
      "eps=0.16, min_samples=240: Everything is a noise!\n",
      "eps=0.16, min_samples=250: Everything is a noise!\n",
      "eps=0.16, min_samples=260: Everything is a noise!\n",
      "eps=0.16, min_samples=270: Everything is a noise!\n",
      "eps=0.16, min_samples=280: Everything is a noise!\n",
      "eps=0.16, min_samples=290: Everything is a noise!\n",
      "eps=0.16, min_samples=300: Everything is a noise!\n",
      "eps=0.16, min_samples=310: Everything is a noise!\n",
      "eps=0.16, min_samples=320: Everything is a noise!\n",
      "eps=0.16, min_samples=330: Everything is a noise!\n",
      "eps=0.16, min_samples=340: Everything is a noise!\n",
      "eps=0.16, min_samples=350: Everything is a noise!\n",
      "eps=0.16, min_samples=360: Everything is a noise!\n",
      "eps=0.16, min_samples=370: Everything is a noise!\n",
      "eps=0.16, min_samples=380: Everything is a noise!\n",
      "eps=0.16, min_samples=390: Everything is a noise!\n",
      "eps=0.16, min_samples=400: Everything is a noise!\n",
      "eps=0.16, min_samples=410: Everything is a noise!\n",
      "eps=0.16, min_samples=420: Everything is a noise!\n",
      "eps=0.16, min_samples=430: Everything is a noise!\n",
      "eps=0.16, min_samples=440: Everything is a noise!\n",
      "eps=0.16, min_samples=450: Everything is a noise!\n",
      "eps=0.16, min_samples=460: Everything is a noise!\n",
      "eps=0.16, min_samples=470: Everything is a noise!\n",
      "eps=0.16, min_samples=480: Everything is a noise!\n",
      "eps=0.16, min_samples=490: Everything is a noise!\n",
      "eps=0.18, min_samples=10: -0.0564\n",
      "eps=0.18, min_samples=20: -0.0409\n",
      "eps=0.18, min_samples=30: -0.0453\n",
      "eps=0.18, min_samples=40: Everything is a noise!\n",
      "eps=0.18, min_samples=50: Everything is a noise!\n",
      "eps=0.18, min_samples=60: Everything is a noise!\n",
      "eps=0.18, min_samples=70: Everything is a noise!\n",
      "eps=0.18, min_samples=80: Everything is a noise!\n",
      "eps=0.18, min_samples=90: Everything is a noise!\n",
      "eps=0.18, min_samples=100: Everything is a noise!\n",
      "eps=0.18, min_samples=110: Everything is a noise!\n",
      "eps=0.18, min_samples=120: Everything is a noise!\n",
      "eps=0.18, min_samples=130: Everything is a noise!\n",
      "eps=0.18, min_samples=140: Everything is a noise!\n",
      "eps=0.18, min_samples=150: Everything is a noise!\n",
      "eps=0.18, min_samples=160: Everything is a noise!\n",
      "eps=0.18, min_samples=170: Everything is a noise!\n",
      "eps=0.18, min_samples=180: Everything is a noise!\n",
      "eps=0.18, min_samples=190: Everything is a noise!\n",
      "eps=0.18, min_samples=200: Everything is a noise!\n",
      "eps=0.18, min_samples=210: Everything is a noise!\n",
      "eps=0.18, min_samples=220: Everything is a noise!\n",
      "eps=0.18, min_samples=230: Everything is a noise!\n",
      "eps=0.18, min_samples=240: Everything is a noise!\n",
      "eps=0.18, min_samples=250: Everything is a noise!\n",
      "eps=0.18, min_samples=260: Everything is a noise!\n",
      "eps=0.18, min_samples=270: Everything is a noise!\n",
      "eps=0.18, min_samples=280: Everything is a noise!\n",
      "eps=0.18, min_samples=290: Everything is a noise!\n",
      "eps=0.18, min_samples=300: Everything is a noise!\n",
      "eps=0.18, min_samples=310: Everything is a noise!\n",
      "eps=0.18, min_samples=320: Everything is a noise!\n",
      "eps=0.18, min_samples=330: Everything is a noise!\n",
      "eps=0.18, min_samples=340: Everything is a noise!\n",
      "eps=0.18, min_samples=350: Everything is a noise!\n",
      "eps=0.18, min_samples=360: Everything is a noise!\n",
      "eps=0.18, min_samples=370: Everything is a noise!\n",
      "eps=0.18, min_samples=380: Everything is a noise!\n",
      "eps=0.18, min_samples=390: Everything is a noise!\n",
      "eps=0.18, min_samples=400: Everything is a noise!\n",
      "eps=0.18, min_samples=410: Everything is a noise!\n",
      "eps=0.18, min_samples=420: Everything is a noise!\n",
      "eps=0.18, min_samples=430: Everything is a noise!\n",
      "eps=0.18, min_samples=440: Everything is a noise!\n",
      "eps=0.18, min_samples=450: Everything is a noise!\n",
      "eps=0.18, min_samples=460: Everything is a noise!\n",
      "eps=0.18, min_samples=470: Everything is a noise!\n",
      "eps=0.18, min_samples=480: Everything is a noise!\n",
      "eps=0.18, min_samples=490: Everything is a noise!\n",
      "eps=0.2, min_samples=10: -0.1256\n",
      "eps=0.2, min_samples=20: -0.039\n",
      "eps=0.2, min_samples=30: -0.039\n",
      "eps=0.2, min_samples=40: Everything is a noise!\n",
      "eps=0.2, min_samples=50: Everything is a noise!\n",
      "eps=0.2, min_samples=60: Everything is a noise!\n",
      "eps=0.2, min_samples=70: Everything is a noise!\n",
      "eps=0.2, min_samples=80: Everything is a noise!\n",
      "eps=0.2, min_samples=90: Everything is a noise!\n",
      "eps=0.2, min_samples=100: Everything is a noise!\n",
      "eps=0.2, min_samples=110: Everything is a noise!\n",
      "eps=0.2, min_samples=120: Everything is a noise!\n",
      "eps=0.2, min_samples=130: Everything is a noise!\n",
      "eps=0.2, min_samples=140: Everything is a noise!\n",
      "eps=0.2, min_samples=150: Everything is a noise!\n",
      "eps=0.2, min_samples=160: Everything is a noise!\n",
      "eps=0.2, min_samples=170: Everything is a noise!\n",
      "eps=0.2, min_samples=180: Everything is a noise!\n",
      "eps=0.2, min_samples=190: Everything is a noise!\n",
      "eps=0.2, min_samples=200: Everything is a noise!\n",
      "eps=0.2, min_samples=210: Everything is a noise!\n",
      "eps=0.2, min_samples=220: Everything is a noise!\n",
      "eps=0.2, min_samples=230: Everything is a noise!\n",
      "eps=0.2, min_samples=240: Everything is a noise!\n",
      "eps=0.2, min_samples=250: Everything is a noise!\n",
      "eps=0.2, min_samples=260: Everything is a noise!\n",
      "eps=0.2, min_samples=270: Everything is a noise!\n",
      "eps=0.2, min_samples=280: Everything is a noise!\n",
      "eps=0.2, min_samples=290: Everything is a noise!\n",
      "eps=0.2, min_samples=300: Everything is a noise!\n",
      "eps=0.2, min_samples=310: Everything is a noise!\n",
      "eps=0.2, min_samples=320: Everything is a noise!\n",
      "eps=0.2, min_samples=330: Everything is a noise!\n",
      "eps=0.2, min_samples=340: Everything is a noise!\n",
      "eps=0.2, min_samples=350: Everything is a noise!\n",
      "eps=0.2, min_samples=360: Everything is a noise!\n",
      "eps=0.2, min_samples=370: Everything is a noise!\n",
      "eps=0.2, min_samples=380: Everything is a noise!\n",
      "eps=0.2, min_samples=390: Everything is a noise!\n",
      "eps=0.2, min_samples=400: Everything is a noise!\n",
      "eps=0.2, min_samples=410: Everything is a noise!\n",
      "eps=0.2, min_samples=420: Everything is a noise!\n",
      "eps=0.2, min_samples=430: Everything is a noise!\n",
      "eps=0.2, min_samples=440: Everything is a noise!\n",
      "eps=0.2, min_samples=450: Everything is a noise!\n",
      "eps=0.2, min_samples=460: Everything is a noise!\n",
      "eps=0.2, min_samples=470: Everything is a noise!\n",
      "eps=0.2, min_samples=480: Everything is a noise!\n",
      "eps=0.2, min_samples=490: Everything is a noise!\n"
     ]
    }
   ],
   "source": [
    "range_eps = np.linspace(start=0.01, stop=0.2, num=10)\n",
    "range_min_samples = range(10, 500, 10)\n",
    "\n",
    "search_results = dbscan_gridsearch(X_clean, range_eps, range_min_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "4062bd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0.2, 20), -0.03902208106690143),\n",
       " ((0.2, 30), -0.03902208106690143),\n",
       " ((0.1788888888888889, 20), -0.040880393203149304),\n",
       " ((0.1577777777777778, 20), -0.04225931614992132),\n",
       " ((0.1788888888888889, 30), -0.04531417026827514),\n",
       " ((0.1366666666666667, 20), -0.048769096508936974),\n",
       " ((0.11555555555555555, 10), -0.0521953834625104),\n",
       " ((0.11555555555555555, 20), -0.054724861153899025),\n",
       " ((0.09444444444444444, 10), -0.05613524324959747),\n",
       " ((0.1788888888888889, 10), -0.05636236292554684),\n",
       " ((0.1577777777777778, 10), -0.057364984898771475),\n",
       " ((0.1366666666666667, 10), -0.06137952073458132),\n",
       " ((0.07333333333333333, 10), -0.06887136238044682),\n",
       " ((0.2, 10), -0.12555738675817793)]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "ba48e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = DBSCAN(eps=0.2, min_samples=20).fit(X_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "a1ee7d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   -1 17744]\n",
      " [    0    37]\n",
      " [    1    31]\n",
      " [    2   823]\n",
      " [    3   350]\n",
      " [    4    20]\n",
      " [    5    46]\n",
      " [    6   716]\n",
      " [    7   111]\n",
      " [    8    64]\n",
      " [    9   139]\n",
      " [   10    28]\n",
      " [   11    20]\n",
      " [   12    79]\n",
      " [   13    26]\n",
      " [   14    52]\n",
      " [   15    48]\n",
      " [   16    77]\n",
      " [   17    21]\n",
      " [   18    53]]\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(np.unique(clustering.labels_, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98cb076",
   "metadata": {},
   "source": [
    "Whelp, that's not very helpful lol\n",
    "There is so much noise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397dea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
